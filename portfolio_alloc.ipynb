{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mxgof6dq8Rg9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "# from finrl.config import config\n",
    "from finrl.neo_finrl.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.neo_finrl.env_portfolio_allocation.portfolio_allocation import StockPortfolioEnv\n",
    "\n",
    "from finrl.drl_agents.stablebaselines3.models import DRLAgent\n",
    "# from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RshlaPitreyq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('usdt_1h_ada_algo_btc_eth_tur.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "start_time = df['date'][0]\n",
    "end_time = df['date'][len(df) - 1]\n",
    "technical_indicators = ['boll_ub',\n",
    " 'boll_lb',\n",
    " 'rsi_56',\n",
    " 'rsi_336',\n",
    " 'rsi_2352',\n",
    " 'cci_56',\n",
    " 'dx_56',\n",
    " 'close_4_sma',\n",
    " 'close_72_sma',\n",
    " 'close_48_ema',\n",
    " 'close_104_ema',\n",
    " 'close_36_ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHCBx_eEaETl",
    "outputId": "4fa796f6-567c-459a-fd34-5aea4bc78a3f"
   },
   "outputs": [],
   "source": [
    "df = df[['date', 'open', 'high', 'low', 'close', 'volume', 'tic']]\n",
    "\n",
    "# df.loc[df['tic'] == 'BTC_USDT', 'open'] /= 10000\n",
    "# df.loc[df['tic'] == 'BTC_USDT', 'close'] /= 10000\n",
    "# df.loc[df['tic'] == 'BTC_USDT', 'high'] /= 10000\n",
    "# df.loc[df['tic'] == 'BTC_USDT', 'low'] /= 10000\n",
    "# df.loc[df['tic'] == 'BTC_USDT', 'volume'] *= 10000\n",
    "\n",
    "# df.loc[df['tic'] == 'ETH_USDT', 'open'] /= 1000\n",
    "# df.loc[df['tic'] == 'ETH_USDT', 'close'] /= 1000\n",
    "# df.loc[df['tic'] == 'ETH_USDT', 'high'] /= 1000\n",
    "# df.loc[df['tic'] == 'ETH_USDT', 'low'] /= 1000\n",
    "# df.loc[df['tic'] == 'ETH_USDT', 'volume'] *= 1000\n",
    "\n",
    "# df.loc[df['tic'] == 'ADA_USDT', 'open'] /= 10\n",
    "# df.loc[df['tic'] == 'ADA_USDT', 'close'] /= 10\n",
    "# df.loc[df['tic'] == 'ADA_USDT', 'high'] /= 10\n",
    "# df.loc[df['tic'] == 'ADA_USDT', 'low'] /= 10\n",
    "# df.loc[df['tic'] == 'ADA_USDT', 'volume'] *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbH-EIAh8Xqw",
    "outputId": "b319eaf1-43a9-4406-8551-246f6113ed33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    use_turbulence=False,\n",
    "                    tech_indicator_list=technical_indicators,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "df = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q_ESpsx6_JwQ"
   },
   "outputs": [],
   "source": [
    "# df.to_csv('/content/drive/MyDrive/data/portfolio_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "bHOUhIUkAL8F",
    "outputId": "5fff6187-ed18-45b7-d562-505790b2d236"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_56</th>\n",
       "      <th>rsi_336</th>\n",
       "      <th>rsi_2352</th>\n",
       "      <th>cci_56</th>\n",
       "      <th>dx_56</th>\n",
       "      <th>close_4_sma</th>\n",
       "      <th>close_72_sma</th>\n",
       "      <th>close_48_ema</th>\n",
       "      <th>close_104_ema</th>\n",
       "      <th>close_36_ema</th>\n",
       "      <th>cov_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 15:00:00</td>\n",
       "      <td>0.05159</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.05155</td>\n",
       "      <td>0.05173</td>\n",
       "      <td>7.368821e+06</td>\n",
       "      <td>ADA_USDT</td>\n",
       "      <td>0.053810</td>\n",
       "      <td>0.049722</td>\n",
       "      <td>53.379375</td>\n",
       "      <td>51.880940</td>\n",
       "      <td>48.377046</td>\n",
       "      <td>1.087486</td>\n",
       "      <td>2.750886</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>0.050154</td>\n",
       "      <td>0.051489</td>\n",
       "      <td>[[0.00010444166579769002, 5.438065070131934e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-20 15:00:00</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.32100</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>7.070001e+04</td>\n",
       "      <td>ALGO_USDT</td>\n",
       "      <td>0.324878</td>\n",
       "      <td>0.315622</td>\n",
       "      <td>48.020831</td>\n",
       "      <td>46.555533</td>\n",
       "      <td>45.433072</td>\n",
       "      <td>-50.938807</td>\n",
       "      <td>4.141416</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.325819</td>\n",
       "      <td>0.322747</td>\n",
       "      <td>0.325008</td>\n",
       "      <td>0.321843</td>\n",
       "      <td>[[0.00010444166579769002, 5.438065070131934e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-20 15:00:00</td>\n",
       "      <td>10157.25000</td>\n",
       "      <td>10189.50000</td>\n",
       "      <td>10125.00000</td>\n",
       "      <td>10140.95000</td>\n",
       "      <td>1.507407e+03</td>\n",
       "      <td>BTC_USDT</td>\n",
       "      <td>10373.562847</td>\n",
       "      <td>9859.947153</td>\n",
       "      <td>49.637721</td>\n",
       "      <td>49.441086</td>\n",
       "      <td>49.852803</td>\n",
       "      <td>27.281361</td>\n",
       "      <td>0.403765</td>\n",
       "      <td>10157.007500</td>\n",
       "      <td>10125.886944</td>\n",
       "      <td>10111.830484</td>\n",
       "      <td>10147.448714</td>\n",
       "      <td>10110.378008</td>\n",
       "      <td>[[0.00010444166579769002, 5.438065070131934e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-20 15:00:00</td>\n",
       "      <td>217.34000</td>\n",
       "      <td>218.24000</td>\n",
       "      <td>216.24000</td>\n",
       "      <td>216.80000</td>\n",
       "      <td>2.097448e+04</td>\n",
       "      <td>ETH_USDT</td>\n",
       "      <td>224.611788</td>\n",
       "      <td>210.138212</td>\n",
       "      <td>58.540904</td>\n",
       "      <td>54.512479</td>\n",
       "      <td>49.055765</td>\n",
       "      <td>72.786074</td>\n",
       "      <td>11.699417</td>\n",
       "      <td>217.195000</td>\n",
       "      <td>211.357222</td>\n",
       "      <td>213.098205</td>\n",
       "      <td>206.738928</td>\n",
       "      <td>214.509011</td>\n",
       "      <td>[[0.00010444166579769002, 5.438065070131934e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-20 16:00:00</td>\n",
       "      <td>0.05173</td>\n",
       "      <td>0.05204</td>\n",
       "      <td>0.05117</td>\n",
       "      <td>0.05185</td>\n",
       "      <td>1.484533e+07</td>\n",
       "      <td>ADA_USDT</td>\n",
       "      <td>0.053817</td>\n",
       "      <td>0.049808</td>\n",
       "      <td>53.599567</td>\n",
       "      <td>51.939663</td>\n",
       "      <td>48.388529</td>\n",
       "      <td>-6.636946</td>\n",
       "      <td>0.124364</td>\n",
       "      <td>0.051683</td>\n",
       "      <td>0.051208</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.050186</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>[[0.00010419746593874823, 5.4345651233928975e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date         open         high          low        close  \\\n",
       "0 2019-09-20 15:00:00      0.05159      0.05205      0.05155      0.05173   \n",
       "1 2019-09-20 15:00:00      0.31900      0.32100      0.31900      0.32000   \n",
       "2 2019-09-20 15:00:00  10157.25000  10189.50000  10125.00000  10140.95000   \n",
       "3 2019-09-20 15:00:00    217.34000    218.24000    216.24000    216.80000   \n",
       "4 2019-09-20 16:00:00      0.05173      0.05204      0.05117      0.05185   \n",
       "\n",
       "         volume        tic       boll_ub      boll_lb     rsi_56    rsi_336  \\\n",
       "0  7.368821e+06   ADA_USDT      0.053810     0.049722  53.379375  51.880940   \n",
       "1  7.070001e+04  ALGO_USDT      0.324878     0.315622  48.020831  46.555533   \n",
       "2  1.507407e+03   BTC_USDT  10373.562847  9859.947153  49.637721  49.441086   \n",
       "3  2.097448e+04   ETH_USDT    224.611788   210.138212  58.540904  54.512479   \n",
       "4  1.484533e+07   ADA_USDT      0.053817     0.049808  53.599567  51.939663   \n",
       "\n",
       "    rsi_2352     cci_56      dx_56   close_4_sma  close_72_sma  close_48_ema  \\\n",
       "0  48.377046   1.087486   2.750886      0.051348      0.051148      0.051313   \n",
       "1  45.433072 -50.938807   4.141416      0.319500      0.325819      0.322747   \n",
       "2  49.852803  27.281361   0.403765  10157.007500  10125.886944  10111.830484   \n",
       "3  49.055765  72.786074  11.699417    217.195000    211.357222    213.098205   \n",
       "4  48.388529  -6.636946   0.124364      0.051683      0.051208      0.051335   \n",
       "\n",
       "   close_104_ema  close_36_ema  \\\n",
       "0       0.050154      0.051489   \n",
       "1       0.325008      0.321843   \n",
       "2   10147.448714  10110.378008   \n",
       "3     206.738928    214.509011   \n",
       "4       0.050186      0.051508   \n",
       "\n",
       "                                            cov_list  \n",
       "0  [[0.00010444166579769002, 5.438065070131934e-0...  \n",
       "1  [[0.00010444166579769002, 5.438065070131934e-0...  \n",
       "2  [[0.00010444166579769002, 5.438065070131934e-0...  \n",
       "3  [[0.00010444166579769002, 5.438065070131934e-0...  \n",
       "4  [[0.00010419746593874823, 5.4345651233928975e-...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add covariance matrix as states\n",
    "df=df.sort_values(['date','tic'],ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "# look back is one year\n",
    "lookback=720*3\n",
    "for i in range(lookback,len(df.index.unique())):\n",
    "  data_lookback = df.loc[i-lookback:i,:]\n",
    "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "  return_lookback = price_lookback.pct_change().dropna()\n",
    "  covs = return_lookback.cov().values \n",
    "  cov_list.append(covs)\n",
    "  \n",
    "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date','tic']).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHWWB7I9ANEc",
    "outputId": "410dfd69-5c49-48f9-d5a7-830d446f011f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67252,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cov_list'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkM6Anw9CH2z",
    "outputId": "d25f224b-8f3f-40b8-aef1-b55634672bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47852\n",
      "19396\n"
     ]
    }
   ],
   "source": [
    "end_train = '2021-01-31 23:00:00'\n",
    "train = data_split(df, start_time, end_train)\n",
    "trade = data_split(df, end_train, end_time)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "jivtXbBSEAC_",
    "outputId": "31514df1-9284-4e23-ef9e-9ea639382640"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_56</th>\n",
       "      <th>rsi_336</th>\n",
       "      <th>rsi_2352</th>\n",
       "      <th>cci_56</th>\n",
       "      <th>dx_56</th>\n",
       "      <th>close_4_sma</th>\n",
       "      <th>close_72_sma</th>\n",
       "      <th>close_48_ema</th>\n",
       "      <th>close_104_ema</th>\n",
       "      <th>close_36_ema</th>\n",
       "      <th>cov_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 15:00:00</td>\n",
       "      <td>0.05159</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.05155</td>\n",
       "      <td>0.05173</td>\n",
       "      <td>7.368821e+06</td>\n",
       "      <td>ADA_USDT</td>\n",
       "      <td>0.053810</td>\n",
       "      <td>0.049722</td>\n",
       "      <td>53.379375</td>\n",
       "      <td>51.880940</td>\n",
       "      <td>48.377046</td>\n",
       "      <td>1.087486</td>\n",
       "      <td>2.750886</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>0.050154</td>\n",
       "      <td>0.051489</td>\n",
       "      <td>[[0.00010444166579769002, 5.438065070131934e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 15:00:00</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.32100</td>\n",
       "      <td>0.31900</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>7.070001e+04</td>\n",
       "      <td>ALGO_USDT</td>\n",
       "      <td>0.324878</td>\n",
       "      <td>0.315622</td>\n",
       "      <td>48.020831</td>\n",
       "      <td>46.555533</td>\n",
       "      <td>45.433072</td>\n",
       "      <td>-50.938807</td>\n",
       "      <td>4.141416</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.325819</td>\n",
       "      <td>0.322747</td>\n",
       "      <td>0.325008</td>\n",
       "      <td>0.321843</td>\n",
       "      <td>[[0.00010444166579769002, 5.438065070131934e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 15:00:00</td>\n",
       "      <td>10157.25000</td>\n",
       "      <td>10189.50000</td>\n",
       "      <td>10125.00000</td>\n",
       "      <td>10140.95000</td>\n",
       "      <td>1.507407e+03</td>\n",
       "      <td>BTC_USDT</td>\n",
       "      <td>10373.562847</td>\n",
       "      <td>9859.947153</td>\n",
       "      <td>49.637721</td>\n",
       "      <td>49.441086</td>\n",
       "      <td>49.852803</td>\n",
       "      <td>27.281361</td>\n",
       "      <td>0.403765</td>\n",
       "      <td>10157.007500</td>\n",
       "      <td>10125.886944</td>\n",
       "      <td>10111.830484</td>\n",
       "      <td>10147.448714</td>\n",
       "      <td>10110.378008</td>\n",
       "      <td>[[0.00010444166579769002, 5.438065070131934e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-20 15:00:00</td>\n",
       "      <td>217.34000</td>\n",
       "      <td>218.24000</td>\n",
       "      <td>216.24000</td>\n",
       "      <td>216.80000</td>\n",
       "      <td>2.097448e+04</td>\n",
       "      <td>ETH_USDT</td>\n",
       "      <td>224.611788</td>\n",
       "      <td>210.138212</td>\n",
       "      <td>58.540904</td>\n",
       "      <td>54.512479</td>\n",
       "      <td>49.055765</td>\n",
       "      <td>72.786074</td>\n",
       "      <td>11.699417</td>\n",
       "      <td>217.195000</td>\n",
       "      <td>211.357222</td>\n",
       "      <td>213.098205</td>\n",
       "      <td>206.738928</td>\n",
       "      <td>214.509011</td>\n",
       "      <td>[[0.00010444166579769002, 5.438065070131934e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-20 16:00:00</td>\n",
       "      <td>0.05173</td>\n",
       "      <td>0.05204</td>\n",
       "      <td>0.05117</td>\n",
       "      <td>0.05185</td>\n",
       "      <td>1.484533e+07</td>\n",
       "      <td>ADA_USDT</td>\n",
       "      <td>0.053817</td>\n",
       "      <td>0.049808</td>\n",
       "      <td>53.599567</td>\n",
       "      <td>51.939663</td>\n",
       "      <td>48.388529</td>\n",
       "      <td>-6.636946</td>\n",
       "      <td>0.124364</td>\n",
       "      <td>0.051683</td>\n",
       "      <td>0.051208</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.050186</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>[[0.00010419746593874823, 5.4345651233928975e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date         open         high          low        close  \\\n",
       "0 2019-09-20 15:00:00      0.05159      0.05205      0.05155      0.05173   \n",
       "0 2019-09-20 15:00:00      0.31900      0.32100      0.31900      0.32000   \n",
       "0 2019-09-20 15:00:00  10157.25000  10189.50000  10125.00000  10140.95000   \n",
       "0 2019-09-20 15:00:00    217.34000    218.24000    216.24000    216.80000   \n",
       "1 2019-09-20 16:00:00      0.05173      0.05204      0.05117      0.05185   \n",
       "\n",
       "         volume        tic       boll_ub      boll_lb     rsi_56    rsi_336  \\\n",
       "0  7.368821e+06   ADA_USDT      0.053810     0.049722  53.379375  51.880940   \n",
       "0  7.070001e+04  ALGO_USDT      0.324878     0.315622  48.020831  46.555533   \n",
       "0  1.507407e+03   BTC_USDT  10373.562847  9859.947153  49.637721  49.441086   \n",
       "0  2.097448e+04   ETH_USDT    224.611788   210.138212  58.540904  54.512479   \n",
       "1  1.484533e+07   ADA_USDT      0.053817     0.049808  53.599567  51.939663   \n",
       "\n",
       "    rsi_2352     cci_56      dx_56   close_4_sma  close_72_sma  close_48_ema  \\\n",
       "0  48.377046   1.087486   2.750886      0.051348      0.051148      0.051313   \n",
       "0  45.433072 -50.938807   4.141416      0.319500      0.325819      0.322747   \n",
       "0  49.852803  27.281361   0.403765  10157.007500  10125.886944  10111.830484   \n",
       "0  49.055765  72.786074  11.699417    217.195000    211.357222    213.098205   \n",
       "1  48.388529  -6.636946   0.124364      0.051683      0.051208      0.051335   \n",
       "\n",
       "   close_104_ema  close_36_ema  \\\n",
       "0       0.050154      0.051489   \n",
       "0       0.325008      0.321843   \n",
       "0   10147.448714  10110.378008   \n",
       "0     206.738928    214.509011   \n",
       "1       0.050186      0.051508   \n",
       "\n",
       "                                            cov_list  \n",
       "0  [[0.00010444166579769002, 5.438065070131934e-0...  \n",
       "0  [[0.00010444166579769002, 5.438065070131934e-0...  \n",
       "0  [[0.00010444166579769002, 5.438065070131934e-0...  \n",
       "0  [[0.00010444166579769002, 5.438065070131934e-0...  \n",
       "1  [[0.00010419746593874823, 5.4345651233928975e-...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLEC-gr1EBzq",
    "outputId": "68eed953-0170-48ae-e0a5-ad68f301cb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 4, State Space: 4\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kGNduJ12EKAb"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"initial_amount\": 100000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": technical_indicators, \n",
    "    \"action_space\": stock_dimension + 1, \n",
    "    \"reward_scaling\": 1e-2,\n",
    "    \"min_trans_amount\": [1, 0, 5, 4]\n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sFLWvatEQLf",
    "outputId": "32a6da30-b4cb-4bac-bbde-f559a5d2204a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "533u69E7IpBf"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "#     os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "# if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "#     os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "# if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "#     os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "# if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "#     os.makedirs(\"./\" + config.RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQ6qwya2EV_f",
    "outputId": "c83ea744-88cd-4e56-945b-2f17eff5ab07",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0003}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_15\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -39       |\n",
      "|    reward             | 6.8329268 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 40.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -5.77     |\n",
      "|    reward             | -1.346594 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.02      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 295       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -78.3     |\n",
      "|    reward             | 2.9925585 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 122       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 309       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    reward             | 2.0048008 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 7.8       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -0.0502    |\n",
      "|    reward             | -2.7071354 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.483      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.09        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0003       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -4.57        |\n",
      "|    reward             | 0.0076181716 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 3.33         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 337        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 4.95       |\n",
      "|    reward             | -1.0427892 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 5.85       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 343         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.11       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -3.5        |\n",
      "|    reward             | -0.04203681 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 346        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 1.96       |\n",
      "|    reward             | -1.5191325 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.876      |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 350            |\n",
      "|    iterations         | 1000           |\n",
      "|    time_elapsed       | 14             |\n",
      "|    total_timesteps    | 5000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.09          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0003         |\n",
      "|    n_updates          | 999            |\n",
      "|    policy_loss        | -6.26          |\n",
      "|    reward             | -0.00036390033 |\n",
      "|    std                | 0.999          |\n",
      "|    value_loss         | 0.936          |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 352        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -5.2       |\n",
      "|    reward             | 0.15615182 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 0.767      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 352        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0.0738     |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 6.52       |\n",
      "|    reward             | -0.8866252 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.822      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 10.1       |\n",
      "|    reward             | 0.70295227 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 357       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 2.75      |\n",
      "|    reward             | 0.6414327 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.352     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 358         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -2.17       |\n",
      "|    reward             | -0.27824968 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 360         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.11       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | -29.3       |\n",
      "|    reward             | -0.11962066 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 22.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 360       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 5.49      |\n",
      "|    reward             | 0.5113442 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.902     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 351         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.13       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.195       |\n",
      "|    reward             | -0.63107693 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.537       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 344        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -0.319     |\n",
      "|    reward             | 0.38868028 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.293      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 343        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.14      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 0.721      |\n",
      "|    reward             | 0.72921014 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.51       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 339       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 5.55      |\n",
      "|    reward             | 1.4944816 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 341       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -9.22     |\n",
      "|    reward             | 0.4224185 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.01      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 17.4        |\n",
      "|    reward             | -0.36513153 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 6.93        |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:100000\n",
      "end_total_asset:100000\n",
      "Sharpe:  nan\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 343       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -7.55     |\n",
      "|    reward             | 0.5743502 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.8       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 344        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -18        |\n",
      "|    reward             | -1.0824219 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 10.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 345        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 24.8       |\n",
      "|    reward             | -1.1441753 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 87.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 346       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -2.9      |\n",
      "|    reward             | 0.6726446 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.92      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 347        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -1.91      |\n",
      "|    reward             | -1.6883006 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.318      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 348       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 8.18      |\n",
      "|    reward             | 0.8959562 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 3.42      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -0.506    |\n",
      "|    reward             | -0.923246 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.86      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 348         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.1        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 26.7        |\n",
      "|    reward             | -0.56116635 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 27.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 348       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.11     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 3.21      |\n",
      "|    reward             | 2.7547717 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.68      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.12    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0003   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 4.17     |\n",
      "|    reward             | 1.038358 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.29     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 347       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 16.5      |\n",
      "|    reward             | 1.6025742 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 6.78      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 347        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | -4.12      |\n",
      "|    reward             | 0.97079813 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 348        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -2.06      |\n",
      "|    reward             | -1.1961519 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 349        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -14.7      |\n",
      "|    reward             | -0.8595561 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.54       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 349        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | -8.54      |\n",
      "|    reward             | -0.9191483 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.6        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 350        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 11.9       |\n",
      "|    reward             | -2.1472304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.1        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 350      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0003   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    reward             | -2.14324 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.7      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.14     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 21.1      |\n",
      "|    reward             | 1.2813807 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 350        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.14      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | -0.0705    |\n",
      "|    reward             | -2.6944711 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.498      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 350         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.13       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -0.79       |\n",
      "|    reward             | -0.45605794 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.747       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 351         |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.15       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | -14.5       |\n",
      "|    reward             | -0.66411865 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 351         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.16       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 8.99        |\n",
      "|    reward             | -0.38387632 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 4.24        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0003   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -15.3    |\n",
      "|    reward             | 2.530946 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.02     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 352        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.17      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | 24.2       |\n",
      "|    reward             | -0.3393311 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 11.1       |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:100000\n",
      "end_total_asset:100000\n",
      "Sharpe:  nan\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 352        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.18      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -29.4      |\n",
      "|    reward             | -1.0505296 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 19.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.18     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 34.3      |\n",
      "|    reward             | 1.0290354 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 28.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.18     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 27.4      |\n",
      "|    reward             | 3.3184984 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.18     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 5.38      |\n",
      "|    reward             | 0.3404931 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 352         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.18       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -0.118      |\n",
      "|    reward             | -0.48632857 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 4.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 353        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 17         |\n",
      "|    reward             | -1.8818064 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.91       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 353        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | 10.2       |\n",
      "|    reward             | 0.79568166 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.63       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 353        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 77         |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | -5.01      |\n",
      "|    reward             | -2.3586981 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 10.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 353       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 7.66      |\n",
      "|    reward             | -3.805026 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.77      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 353        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.2       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | 0.897      |\n",
      "|    reward             | -1.8858244 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.734      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 354       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -9.58     |\n",
      "|    reward             | -10.10025 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 6.02      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 354        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -51.6      |\n",
      "|    reward             | -3.8007808 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 47.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 84         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.2       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 49         |\n",
      "|    reward             | 0.70038736 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 72.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.2      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -19.1     |\n",
      "|    reward             | -1.741063 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.74      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.2      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 39.2      |\n",
      "|    reward             | 1.855173  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 49.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.2      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 11.2      |\n",
      "|    reward             | 3.0968578 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.98      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 32.2      |\n",
      "|    reward             | 3.2227786 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 51.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 356        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 13.1       |\n",
      "|    reward             | -3.1469676 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 9.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 354        |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -34.8      |\n",
      "|    reward             | -0.2625661 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 24.2       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 352         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.22       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -44.2       |\n",
      "|    reward             | 0.016895797 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 55.5        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 351        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 96         |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 22.5       |\n",
      "|    reward             | 0.24413963 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 14.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 349        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 98         |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -95        |\n",
      "|    reward             | -2.9516177 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 185        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 349        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 100        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 52.3       |\n",
      "|    reward             | -1.1270266 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 69.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 16.1      |\n",
      "|    reward             | -5.677445 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 86.5      |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:100000\n",
      "end_total_asset:100000\n",
      "Sharpe:  nan\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -525      |\n",
      "|    reward             | -15.55681 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.56e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -30.8     |\n",
      "|    reward             | 0.4495629 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 28.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 350      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.21    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0003   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 15.8     |\n",
      "|    reward             | 9.128243 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.22     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -17.2     |\n",
      "|    reward             | 1.6821502 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 18.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -3.13     |\n",
      "|    reward             | 1.9586791 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 7.38      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 350        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 109        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | 9.93       |\n",
      "|    reward             | 0.28472784 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 7.28       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 350        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 111        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | -6.38      |\n",
      "|    reward             | -1.0217578 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 6.41       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 54.4      |\n",
      "|    reward             | -7.584165 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 72.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 351        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 7.61       |\n",
      "|    reward             | -2.9810228 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 10.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 351        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 6.76       |\n",
      "|    reward             | -2.6741245 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.67       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 351        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 116        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -29.3      |\n",
      "|    reward             | -0.2780836 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 25         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 34.6      |\n",
      "|    reward             | -7.498359 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 30.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0003   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.969    |\n",
      "|    reward             | 2.011206 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.55     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 16.2      |\n",
      "|    reward             | 1.1511906 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 9.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 353       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 0.86      |\n",
      "|    reward             | 1.0853698 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.03      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 353         |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.22       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | -22.9       |\n",
      "|    reward             | -0.13581155 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 11          |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 353        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 32.1       |\n",
      "|    reward             | -2.1937802 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 17.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 353        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | -0.0879    |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -20.9      |\n",
      "|    reward             | 0.96457785 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 26.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 353        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 127        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | -7.98      |\n",
      "|    reward             | -1.1421909 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.36       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 354         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.2        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | -11.2       |\n",
      "|    reward             | -0.07776045 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.38        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 354        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 129        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.2       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | -4.11      |\n",
      "|    reward             | 0.29681876 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.389      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 354         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.19       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | 7.25        |\n",
      "|    reward             | -0.10021126 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 354         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.2        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -0.4        |\n",
      "|    reward             | -0.02556341 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.596       |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.2     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0003   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -16.5    |\n",
      "|    reward             | 4.076953 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:100000\n",
      "end_total_asset:100000\n",
      "Sharpe:  nan\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0003   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    reward             | 5.743412 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 354       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 0.378     |\n",
      "|    reward             | 6.3814487 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.612     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 354         |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.19       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | 19.8        |\n",
      "|    reward             | -0.88594884 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 12.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 354        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 139        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.2       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | -18.2      |\n",
      "|    reward             | -1.0390981 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.31       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 140        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 63.2       |\n",
      "|    reward             | -5.9153857 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 86.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 354       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -29.9     |\n",
      "|    reward             | 2.0824232 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -19.1     |\n",
      "|    reward             | 2.0437815 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 10300      |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 51500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.2       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 10299      |\n",
      "|    policy_loss        | 34         |\n",
      "|    reward             | 10.9815855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 25.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 10400      |\n",
      "|    time_elapsed       | 146        |\n",
      "|    total_timesteps    | 52000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 10399      |\n",
      "|    policy_loss        | -23        |\n",
      "|    reward             | -2.7564497 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 13.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 10500      |\n",
      "|    time_elapsed       | 147        |\n",
      "|    total_timesteps    | 52500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.2       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 10499      |\n",
      "|    policy_loss        | -5.6       |\n",
      "|    reward             | 0.36357978 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2          |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 10600      |\n",
      "|    time_elapsed       | 149        |\n",
      "|    total_timesteps    | 53000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.2       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 10599      |\n",
      "|    policy_loss        | 3.86       |\n",
      "|    reward             | 0.47683534 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.08       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 10700      |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 53500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.19      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | 8.33       |\n",
      "|    reward             | -1.7808229 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 355        |\n",
      "|    iterations         | 10800      |\n",
      "|    time_elapsed       | 151        |\n",
      "|    total_timesteps    | 54000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 10799      |\n",
      "|    policy_loss        | 10.6       |\n",
      "|    reward             | -2.0390944 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.1        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | 6.45      |\n",
      "|    reward             | 0.2325237 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.96      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 355         |\n",
      "|    iterations         | 11000       |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 55000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.2        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0003      |\n",
      "|    n_updates          | 10999       |\n",
      "|    policy_loss        | 10.5        |\n",
      "|    reward             | -0.26535556 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 4.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 354        |\n",
      "|    iterations         | 11100      |\n",
      "|    time_elapsed       | 156        |\n",
      "|    total_timesteps    | 55500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 11099      |\n",
      "|    policy_loss        | -22.1      |\n",
      "|    reward             | -4.0937505 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 14.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 354        |\n",
      "|    iterations         | 11200      |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 56000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 11199      |\n",
      "|    policy_loss        | -37.4      |\n",
      "|    reward             | -4.0780644 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 354       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.22     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -1.37     |\n",
      "|    reward             | -2.247773 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.36      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 352        |\n",
      "|    iterations         | 11400      |\n",
      "|    time_elapsed       | 161        |\n",
      "|    total_timesteps    | 57000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 11399      |\n",
      "|    policy_loss        | 7.49       |\n",
      "|    reward             | 0.34365964 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 1.19       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -2.94     |\n",
      "|    reward             | 1.0593362 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 9.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.22     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | 15        |\n",
      "|    reward             | 1.5142449 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 7.62      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 348        |\n",
      "|    iterations         | 11700      |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 58500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 11699      |\n",
      "|    policy_loss        | 8.64       |\n",
      "|    reward             | -1.2960978 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.79       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -0.0414   |\n",
      "|    reward             | 2.3614552 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.65      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0003    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 49.1      |\n",
      "|    reward             | 1.3926857 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 70        |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:100000\n",
      "end_total_asset:100000\n",
      "Sharpe:  nan\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 349        |\n",
      "|    iterations         | 12000      |\n",
      "|    time_elapsed       | 171        |\n",
      "|    total_timesteps    | 60000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0003     |\n",
      "|    n_updates          | 11999      |\n",
      "|    policy_loss        | 28.3       |\n",
      "|    reward             | -1.1306581 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 38.8       |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "a2c_params_tuning = {'n_steps':5, \n",
    "                     'ent_coef':0.005, \n",
    "                     'learning_rate':0.0003,\n",
    "}\n",
    "model_a2c = agent.get_model(\"a2c\",model_kwargs=a2c_params_tuning)\n",
    "trained_a2c = agent.train_model(model= model_a2c, tb_log_name= \"a2c\", total_timesteps= 60000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6sbw1lm3Erli"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BpYDypFCLSZ9",
    "outputId": "208fcd7d-f751-4386-cb15-96f8be21ee77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:100000\n",
      "end_total_asset:100000\n",
      "Sharpe:  nan\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_daily_return, df_actions, _, _ = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "C7m8PbbhLUu0",
    "outputId": "999a927c-7964-4245-ab58-cb38e66e27ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31 23:00:00</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-01 00:00:00</td>\n",
       "      <td>98030.823500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-01 01:00:00</td>\n",
       "      <td>97658.003207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01 02:00:00</td>\n",
       "      <td>99410.129834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-01 03:00:00</td>\n",
       "      <td>98609.292310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>2021-08-22 06:00:00</td>\n",
       "      <td>100602.712990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>2021-08-22 07:00:00</td>\n",
       "      <td>101932.635280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>2021-08-22 08:00:00</td>\n",
       "      <td>102844.626648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>2021-08-22 09:00:00</td>\n",
       "      <td>102506.005127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>2021-08-22 10:00:00</td>\n",
       "      <td>103308.742014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4849 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date  account_value\n",
       "0    2021-01-31 23:00:00  100000.000000\n",
       "1    2021-02-01 00:00:00   98030.823500\n",
       "2    2021-02-01 01:00:00   97658.003207\n",
       "3    2021-02-01 02:00:00   99410.129834\n",
       "4    2021-02-01 03:00:00   98609.292310\n",
       "...                  ...            ...\n",
       "4844 2021-08-22 06:00:00  100602.712990\n",
       "4845 2021-08-22 07:00:00  101932.635280\n",
       "4846 2021-08-22 08:00:00  102844.626648\n",
       "4847 2021-08-22 09:00:00  102506.005127\n",
       "4848 2021-08-22 10:00:00  103308.742014\n",
       "\n",
       "[4849 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "v9MjSz-_X3z4",
    "outputId": "f132f5c8-81fd-46f4-d694-6de7671a54fb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cash</th>\n",
       "      <th>ADA_USDT</th>\n",
       "      <th>ALGO_USDT</th>\n",
       "      <th>BTC_USDT</th>\n",
       "      <th>ETH_USDT</th>\n",
       "      <th>cashh</th>\n",
       "      <th>ada</th>\n",
       "      <th>algo</th>\n",
       "      <th>btc</th>\n",
       "      <th>eth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-31 23:00:00</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01 00:00:00</th>\n",
       "      <td>18822.250306</td>\n",
       "      <td>36503.0</td>\n",
       "      <td>52889.0</td>\n",
       "      <td>0.65080</td>\n",
       "      <td>9.6386</td>\n",
       "      <td>0.189033</td>\n",
       "      <td>0.126509</td>\n",
       "      <td>0.343886</td>\n",
       "      <td>0.214063</td>\n",
       "      <td>0.126509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01 01:00:00</th>\n",
       "      <td>28855.664980</td>\n",
       "      <td>31138.3</td>\n",
       "      <td>45840.0</td>\n",
       "      <td>0.59008</td>\n",
       "      <td>8.2321</td>\n",
       "      <td>0.294455</td>\n",
       "      <td>0.108324</td>\n",
       "      <td>0.294455</td>\n",
       "      <td>0.194441</td>\n",
       "      <td>0.108324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01 02:00:00</th>\n",
       "      <td>31453.113506</td>\n",
       "      <td>34193.6</td>\n",
       "      <td>50595.0</td>\n",
       "      <td>0.35671</td>\n",
       "      <td>8.9855</td>\n",
       "      <td>0.322202</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.322202</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.118532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01 03:00:00</th>\n",
       "      <td>22703.798050</td>\n",
       "      <td>65722.8</td>\n",
       "      <td>45999.0</td>\n",
       "      <td>0.33417</td>\n",
       "      <td>10.2251</td>\n",
       "      <td>0.228548</td>\n",
       "      <td>0.227131</td>\n",
       "      <td>0.299801</td>\n",
       "      <td>0.110291</td>\n",
       "      <td>0.134230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-22 06:00:00</th>\n",
       "      <td>32681.748636</td>\n",
       "      <td>4894.3</td>\n",
       "      <td>28024.0</td>\n",
       "      <td>0.24369</td>\n",
       "      <td>3.6968</td>\n",
       "      <td>0.322202</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.322202</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.118532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-22 07:00:00</th>\n",
       "      <td>32414.175878</td>\n",
       "      <td>4898.9</td>\n",
       "      <td>28215.0</td>\n",
       "      <td>0.24424</td>\n",
       "      <td>3.6993</td>\n",
       "      <td>0.322202</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.322202</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>0.118532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-22 08:00:00</th>\n",
       "      <td>10091.011501</td>\n",
       "      <td>10156.0</td>\n",
       "      <td>23170.0</td>\n",
       "      <td>0.56214</td>\n",
       "      <td>3.6357</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>0.244883</td>\n",
       "      <td>0.270026</td>\n",
       "      <td>0.270026</td>\n",
       "      <td>0.115727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-22 09:00:00</th>\n",
       "      <td>27508.604245</td>\n",
       "      <td>10895.5</td>\n",
       "      <td>23010.0</td>\n",
       "      <td>0.20657</td>\n",
       "      <td>3.1171</td>\n",
       "      <td>0.267683</td>\n",
       "      <td>0.267683</td>\n",
       "      <td>0.267683</td>\n",
       "      <td>0.098475</td>\n",
       "      <td>0.098475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-22 10:00:00</th>\n",
       "      <td>31129.369517</td>\n",
       "      <td>4543.8</td>\n",
       "      <td>26205.0</td>\n",
       "      <td>0.35354</td>\n",
       "      <td>3.5497</td>\n",
       "      <td>0.303960</td>\n",
       "      <td>0.111821</td>\n",
       "      <td>0.303960</td>\n",
       "      <td>0.168438</td>\n",
       "      <td>0.111821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4849 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              cash  ADA_USDT  ALGO_USDT  BTC_USDT  ETH_USDT  \\\n",
       "date                                                                          \n",
       "2021-01-31 23:00:00  100000.000000       0.0        0.0   0.00000    0.0000   \n",
       "2021-02-01 00:00:00   18822.250306   36503.0    52889.0   0.65080    9.6386   \n",
       "2021-02-01 01:00:00   28855.664980   31138.3    45840.0   0.59008    8.2321   \n",
       "2021-02-01 02:00:00   31453.113506   34193.6    50595.0   0.35671    8.9855   \n",
       "2021-02-01 03:00:00   22703.798050   65722.8    45999.0   0.33417   10.2251   \n",
       "...                            ...       ...        ...       ...       ...   \n",
       "2021-08-22 06:00:00   32681.748636    4894.3    28024.0   0.24369    3.6968   \n",
       "2021-08-22 07:00:00   32414.175878    4898.9    28215.0   0.24424    3.6993   \n",
       "2021-08-22 08:00:00   10091.011501   10156.0    23170.0   0.56214    3.6357   \n",
       "2021-08-22 09:00:00   27508.604245   10895.5    23010.0   0.20657    3.1171   \n",
       "2021-08-22 10:00:00   31129.369517    4543.8    26205.0   0.35354    3.5497   \n",
       "\n",
       "                        cashh       ada      algo       btc       eth  \n",
       "date                                                                   \n",
       "2021-01-31 23:00:00  1.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2021-02-01 00:00:00  0.189033  0.126509  0.343886  0.214063  0.126509  \n",
       "2021-02-01 01:00:00  0.294455  0.108324  0.294455  0.194441  0.108324  \n",
       "2021-02-01 02:00:00  0.322202  0.118532  0.322202  0.118532  0.118532  \n",
       "2021-02-01 03:00:00  0.228548  0.227131  0.299801  0.110291  0.134230  \n",
       "...                       ...       ...       ...       ...       ...  \n",
       "2021-08-22 06:00:00  0.322202  0.118532  0.322202  0.118532  0.118532  \n",
       "2021-08-22 07:00:00  0.322202  0.118532  0.322202  0.118532  0.118532  \n",
       "2021-08-22 08:00:00  0.099337  0.244883  0.270026  0.270026  0.115727  \n",
       "2021-08-22 09:00:00  0.267683  0.267683  0.267683  0.098475  0.098475  \n",
       "2021-08-22 10:00:00  0.303960  0.111821  0.303960  0.168438  0.111821  \n",
       "\n",
       "[4849 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000000e+00, 3.465700e-01, 6.502000e-01, 3.289186e+04,\n",
       "       1.312510e+03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed = np.append([1] , trade.loc[0].close.values.tolist())\n",
    "closed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cashh    18903.346360\n",
       "ada      12650.869787\n",
       "algo     34388.631582\n",
       "btc      21406.279504\n",
       "eth      12650.869787\n",
       "Name: 2021-02-01 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df_actions[['cashh', 'ada', 'algo', 'btc', 'eth']] \n",
    "test_df.iloc[1] * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_56</th>\n",
       "      <th>rsi_336</th>\n",
       "      <th>rsi_2352</th>\n",
       "      <th>cci_56</th>\n",
       "      <th>dx_56</th>\n",
       "      <th>close_4_sma</th>\n",
       "      <th>close_72_sma</th>\n",
       "      <th>close_48_ema</th>\n",
       "      <th>close_104_ema</th>\n",
       "      <th>close_36_ema</th>\n",
       "      <th>cov_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31 23:00:00</td>\n",
       "      <td>0.34419</td>\n",
       "      <td>0.34680</td>\n",
       "      <td>0.34000</td>\n",
       "      <td>0.34657</td>\n",
       "      <td>1.822425e+07</td>\n",
       "      <td>ADA_USDT</td>\n",
       "      <td>0.372252</td>\n",
       "      <td>0.343087</td>\n",
       "      <td>49.434094</td>\n",
       "      <td>51.319792</td>\n",
       "      <td>52.004164</td>\n",
       "      <td>-83.329619</td>\n",
       "      <td>3.873874</td>\n",
       "      <td>0.347712</td>\n",
       "      <td>0.352132</td>\n",
       "      <td>0.353008</td>\n",
       "      <td>0.349065</td>\n",
       "      <td>0.353935</td>\n",
       "      <td>[[0.0002662892356814467, 0.0001679717184276767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31 23:00:00</td>\n",
       "      <td>0.65460</td>\n",
       "      <td>0.66840</td>\n",
       "      <td>0.64970</td>\n",
       "      <td>0.65020</td>\n",
       "      <td>1.600619e+06</td>\n",
       "      <td>ALGO_USDT</td>\n",
       "      <td>0.678525</td>\n",
       "      <td>0.637315</td>\n",
       "      <td>53.494131</td>\n",
       "      <td>52.660269</td>\n",
       "      <td>51.259631</td>\n",
       "      <td>43.387665</td>\n",
       "      <td>26.935413</td>\n",
       "      <td>0.665275</td>\n",
       "      <td>0.620978</td>\n",
       "      <td>0.642627</td>\n",
       "      <td>0.616427</td>\n",
       "      <td>0.649815</td>\n",
       "      <td>[[0.0002662892356814467, 0.0001679717184276767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31 23:00:00</td>\n",
       "      <td>32862.65000</td>\n",
       "      <td>33073.55000</td>\n",
       "      <td>32555.00000</td>\n",
       "      <td>32891.86000</td>\n",
       "      <td>3.707195e+03</td>\n",
       "      <td>BTC_USDT</td>\n",
       "      <td>34704.267635</td>\n",
       "      <td>32828.498365</td>\n",
       "      <td>48.134553</td>\n",
       "      <td>50.014009</td>\n",
       "      <td>51.890975</td>\n",
       "      <td>-128.409564</td>\n",
       "      <td>19.160449</td>\n",
       "      <td>33194.537500</td>\n",
       "      <td>34196.435000</td>\n",
       "      <td>33820.201227</td>\n",
       "      <td>33541.109954</td>\n",
       "      <td>33808.451218</td>\n",
       "      <td>[[0.0002662892356814467, 0.0001679717184276767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31 23:00:00</td>\n",
       "      <td>1311.01000</td>\n",
       "      <td>1320.00000</td>\n",
       "      <td>1296.29000</td>\n",
       "      <td>1312.51000</td>\n",
       "      <td>6.838198e+04</td>\n",
       "      <td>ETH_USDT</td>\n",
       "      <td>1393.303434</td>\n",
       "      <td>1313.646566</td>\n",
       "      <td>47.634665</td>\n",
       "      <td>51.371315</td>\n",
       "      <td>52.426816</td>\n",
       "      <td>-202.205100</td>\n",
       "      <td>23.240875</td>\n",
       "      <td>1325.952500</td>\n",
       "      <td>1355.960556</td>\n",
       "      <td>1351.097920</td>\n",
       "      <td>1342.764507</td>\n",
       "      <td>1351.125262</td>\n",
       "      <td>[[0.0002662892356814467, 0.0001679717184276767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-01 00:00:00</td>\n",
       "      <td>0.34655</td>\n",
       "      <td>0.34758</td>\n",
       "      <td>0.33961</td>\n",
       "      <td>0.34103</td>\n",
       "      <td>1.451201e+07</td>\n",
       "      <td>ADA_USDT</td>\n",
       "      <td>0.372582</td>\n",
       "      <td>0.340482</td>\n",
       "      <td>48.060355</td>\n",
       "      <td>51.099948</td>\n",
       "      <td>51.939022</td>\n",
       "      <td>-95.049684</td>\n",
       "      <td>2.771485</td>\n",
       "      <td>0.344775</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.352519</td>\n",
       "      <td>0.348912</td>\n",
       "      <td>0.353237</td>\n",
       "      <td>[[0.0002660495491612565, 0.0001681075604836601...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date         open         high          low        close  \\\n",
       "0 2021-01-31 23:00:00      0.34419      0.34680      0.34000      0.34657   \n",
       "0 2021-01-31 23:00:00      0.65460      0.66840      0.64970      0.65020   \n",
       "0 2021-01-31 23:00:00  32862.65000  33073.55000  32555.00000  32891.86000   \n",
       "0 2021-01-31 23:00:00   1311.01000   1320.00000   1296.29000   1312.51000   \n",
       "1 2021-02-01 00:00:00      0.34655      0.34758      0.33961      0.34103   \n",
       "\n",
       "         volume        tic       boll_ub       boll_lb     rsi_56    rsi_336  \\\n",
       "0  1.822425e+07   ADA_USDT      0.372252      0.343087  49.434094  51.319792   \n",
       "0  1.600619e+06  ALGO_USDT      0.678525      0.637315  53.494131  52.660269   \n",
       "0  3.707195e+03   BTC_USDT  34704.267635  32828.498365  48.134553  50.014009   \n",
       "0  6.838198e+04   ETH_USDT   1393.303434   1313.646566  47.634665  51.371315   \n",
       "1  1.451201e+07   ADA_USDT      0.372582      0.340482  48.060355  51.099948   \n",
       "\n",
       "    rsi_2352      cci_56      dx_56   close_4_sma  close_72_sma  close_48_ema  \\\n",
       "0  52.004164  -83.329619   3.873874      0.347712      0.352132      0.353008   \n",
       "0  51.259631   43.387665  26.935413      0.665275      0.620978      0.642627   \n",
       "0  51.890975 -128.409564  19.160449  33194.537500  34196.435000  33820.201227   \n",
       "0  52.426816 -202.205100  23.240875   1325.952500   1355.960556   1351.097920   \n",
       "1  51.939022  -95.049684   2.771485      0.344775      0.352113      0.352519   \n",
       "\n",
       "   close_104_ema  close_36_ema  \\\n",
       "0       0.349065      0.353935   \n",
       "0       0.616427      0.649815   \n",
       "0   33541.109954  33808.451218   \n",
       "0    1342.764507   1351.125262   \n",
       "1       0.348912      0.353237   \n",
       "\n",
       "                                            cov_list  \n",
       "0  [[0.0002662892356814467, 0.0001679717184276767...  \n",
       "0  [[0.0002662892356814467, 0.0001679717184276767...  \n",
       "0  [[0.0002662892356814467, 0.0001679717184276767...  \n",
       "0  [[0.0002662892356814467, 0.0001679717184276767...  \n",
       "1  [[0.0002660495491612565, 0.0001681075604836601...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCezVn3VtvIQ"
   },
   "outputs": [],
   "source": [
    "def calculate_sharpe(df):\n",
    "  df['daily_return'] = df['account_value'].pct_change(1)\n",
    "  if df['daily_return'].std() !=0:\n",
    "    sharpe = df['daily_return'].mean() / df['daily_return'].std()\n",
    "    return sharpe\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkenD0nasibR"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import torch as th\n",
    "\n",
    "def objective_ddpg(ddpg_params):\n",
    "  print(ddpg_params)\n",
    "  e_train_gym = StockPortfolioEnv(df= train, **env_kwargs)\n",
    "  env_train, _ = e_train_gym.get_sb_env()\n",
    "  agent = DRLAgent(env = env_train)\n",
    "  \n",
    "  net_params = dict(activation_fn=th.nn.Tanh, net_arch=list(ddpg_params['net']))\n",
    "  ddpg_params.pop('net')\n",
    "  ddpg_params['buffer_size'] = int(ddpg_params['buffer_size'])\n",
    "  ddpg_params['batch_size'] = int(ddpg_params['batch_size'])\n",
    "\n",
    "  model_ddpg = agent.get_model(\"ddpg\",model_kwargs= ddpg_params, policy_kwargs= net_params)\n",
    "  trained_ddpg = agent.train_model(model= model_ddpg, tb_log_name= \"ddpg\", total_timesteps= 60000)\n",
    "  clear_output(wait= True)\n",
    "  \n",
    "  e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)\n",
    "  df_account_value, df_actions, _, _ = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym)\n",
    "  if -calculate_sharpe(df_account_value) < best_neg_sharpe:\n",
    "    model_ddpg.save(\"/content/drive/MyDrive/data/portfolio_model_ddpg\")\n",
    "  \n",
    "  return {\n",
    "      'loss': -calculate_sharpe(df_account_value),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWvTd6Eqt-SG"
   },
   "outputs": [],
   "source": [
    "net_archs = [[64,64], [96, 96], [128, 128], [64, 128, 128], [96, 128, 128]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIXQ1Efntn4C",
    "outputId": "b7d65dd6-6aa5-4264-ff49-1e85d6bccc1a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "best_neg_sharpe = -0.02\n",
    "best_ddpg = {}\n",
    "\n",
    "for trial in range(30):\n",
    "  net = np.random.randint(0, 5)\n",
    "  buffer_size = np.random.randint(10000, 20000)\n",
    "  batch_size = np.random.randint(100, 200)\n",
    "  learning_rate = np.random.uniform(0.0001, 0.007)\n",
    "  gamma = np.random.uniform(0.97, 0.99)\n",
    "  params = {\n",
    "      \"net\":net_archs[net],\n",
    "      \"buffer_size\":buffer_size,\n",
    "      \"batch_size\":batch_size,\n",
    "      \"learning_rate\":learning_rate,\n",
    "      \"gamma\":gamma\n",
    "  }\n",
    "  res = objective_ddpg(params)\n",
    "  if res['loss'] < best_neg_sharpe:\n",
    "    best_ddpg = params\n",
    "    best_neg_sharpe = res['loss']\n",
    "    print(f\"New best sharpe: {best_ddpg}\")\n",
    "    with open(\"/content/drive/MyDrive/data/portfolio_ddpg_best.txt\", \"w+\") as f:\n",
    "      json.dump(best_ddpg, f)\n",
    "      f.write(f\"\\n\\nbest_neg_sharpe: {best_neg_sharpe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNGessCC1E4X"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_account_values(account_values):\n",
    "  # account_values['baseline'] = baseline_returns['baseline']\n",
    "  account_values.reset_index()\n",
    "  account_values = account_values.set_index('date')\n",
    "\n",
    "  fig = plt.figure(figsize= (15, 10))\n",
    "  sns.lineplot(data=account_values)\n",
    "\n",
    "%matplotlib inline\n",
    "plot_account_values(df_daily_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kEXpZNbp3LM"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLBugBSvGXFg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "portfolio_alloc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
